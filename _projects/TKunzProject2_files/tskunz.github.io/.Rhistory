#Load necessary packages
library(RCurl)
library(tidyverse)
library(stats)
library(caret)
library(e1071)
library(class)
library(pROC)
# Load in data set from Amazon S3
cs2data = read.csv("https://s3.us-east-2.amazonaws.com/msds.ds.6306.2/CaseStudy2-data.csv", stringsAsFactors = TRUE)
# Load in classification competition set
compClassData = read.csv("https://msdsds6306.s3.us-east-2.amazonaws.com/CaseStudy2CompSet+No+Attrition.csv", stringsAsFactors = TRUE)
# load in regression competition set
compSalData = read.csv("https://msdsds6306.s3.us-east-2.amazonaws.com/CaseStudy2CompSet+No+Salary.csv")
#creating a binary fields to assist with classification.
cs2data$AttrBin = ifelse(cs2data$Attrition == "Yes", 1, 0)
cs2data$MF = ifelse(cs2data$Gender == "Male", 1, 0)
cs2data$OT = ifelse(cs2data$OverTime == "Yes", 1, 0)
cs2data$o18 = ifelse(cs2data$Over18 == "Y", 1, 0)
cs2data$Married = ifelse(cs2data$MaritalStatus == "Married", 1, 0)
cs2data$Divorced = ifelse(cs2data$MaritalStatus == "Divorced", 1, 0)
cs2data$Travel = as.numeric(cs2data$BusinessTravel) - 1
cs2data$RND = ifelse(cs2data$Department == "Research & Development", 1, 0)
cs2data$Sales = ifelse(cs2data$Department == "Sales", 1, 0)
cs2data$U30 = ifelse(cs2data$Age < 30, 1, 0)
cs2data$U35 = ifelse(cs2data$Age < 35, 1, 0)
cs2data$U40 = ifelse(cs2data$Age < 40, 1, 0)
cs2data$O45 = ifelse(cs2data$Age > 45, 1, 0)
cs2data$Attrition = relevel(cs2data$Attrition, ref = "Yes")
cs2data$L10 = ifelse(cs2data$TotalWorkingYears <= 10, 1, 0)
cs2data %>% ggplot(aes(x =  EnvironmentSatisfaction, y = OT, color = Attrition)) + geom_jitter(width =.1, length = .1)
# set counter for iterations
iter = 100
# Add variables to measure performance of the model across iterations.
accKNNoriginal = matrix(nrow = iter)
accKNNThreshold = matrix(nrow = iter)
sensKNNoriginal = matrix(nrow = iter)
sensKNNThreshold = matrix(nrow = iter)
specKNNoriginal = matrix(nrow = iter)
specKNNThreshold = matrix(nrow = iter)
selected_k_values = numeric(iter)
# Range of k values to find the optimal K value. Using only odd numbers for tie breakers
k_values = seq(3, 25, by = 2)
# create a loop to iterate through the model
for (s in 1:iter) {
# set seed to s generate replicable for each iteration to measure model performance
set.seed(s)
# Set training and test data sets for the data
trainIndices = sample(seq(1:length(cs2data$Attrition)), round(.7*length(cs2data$Attrition)))
trainData = cs2data[trainIndices,]
testData = cs2data[-trainIndices,]
# Set variables for the best K value and Accuracy metric
best_k = NULL
best_accuracy = 0
# Iterate through the range of k values
for (k in k_values) {
# KNN with variables most correlated with Attrition
classificationsKNN = knn(trainData[, c("OT", "U30", "JobLevel", "JobInvolvement")],
testData[, c("OT", "U30", "JobLevel", "JobInvolvement")],
trainData$Attrition, prob = TRUE, k = k)
# Create confusion matrix for the given iteration
KNNCM = confusionMatrix(classificationsKNN, testData$Attrition)
# Store model performance results
accuracy = KNNCM$overall["Accuracy"]
# Check if the current k gives better accuracy than other stored K values
if (accuracy > best_accuracy) {
best_accuracy = accuracy
best_k = k
}
}
# Display the selected k value
#cat("Iteration:", s, "Selected k:", best_k, "\n")
selected_k_values[s] = best_k
# Use the best k found in the grid search
classificationsKNN = knn(trainData[, c("OT", "JobInvolvement", "U30", "JobLevel")],
testData[, c("OT", "JobInvolvement", "U30", "JobLevel")],
trainData$Attrition, prob = TRUE, k = best_k)
# Create confusion matrix for the given iteration
KNNCM = confusionMatrix(classificationsKNN, testData$Attrition)
# Store model performance results for the original k
accKNNoriginal[s] = KNNCM$overall[c("Accuracy")]
sensKNNoriginal[s] = KNNCM$byClass[c("Sensitivity")]
specKNNoriginal[s] = KNNCM$byClass[c("Specificity")]
# Get probability of Attrition
probAttr = ifelse(classificationsKNN == "Yes", attributes(classificationsKNN)$prob, 1- attributes(classificationsKNN)$prob)
# Resetting the threshold to .2, as it was a little more accurate across the iterations at .2 than the absolute percentage of attrition / (attrition + not attrition) or 140/(140 + 730). Then continued to adjust to get within 60% sensitivity and specificity
NewClassification = ifelse(probAttr > .1519, "Yes", "No")
NC = table(NewClassification, testData$Attrition)
CM_AttrNC = confusionMatrix(table(relevel(as.factor(NewClassification), ref = "Yes"), testData$Attrition), mode = "everything")
# Print results of the confusionMatrix
#  cat("Thresholded k:", best_k, "\n")
#  CM_AttrNC
# Store model performance results for the thresholded k
accKNNThreshold[s] = CM_AttrNC$overall[c("Accuracy")]
sensKNNThreshold[s] = CM_AttrNC$byClass[c("Sensitivity")]
specKNNThreshold[s] = CM_AttrNC$byClass[c("Specificity")]
}
# printing out which k value is selected to determine the best k
table(selected_k_values) #3 is usually the best k.
# set counter for iterations
iter = 100
# Add variables to measure performance of the model across iterations.
accKNNoriginal = matrix(nrow = iter)
accKNNThreshold = matrix(nrow = iter)
sensKNNoriginal = matrix(nrow = iter)
sensKNNThreshold = matrix(nrow = iter)
specKNNoriginal = matrix(nrow = iter)
specKNNThreshold = matrix(nrow = iter)
# create a loop to iterate through the model
for (s in 1:iter){
#set seed to s generate reproducibility for each iteration to measure model performance
set.seed(s)
# Set training and test data sets for the data
trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.70*length(cs2data$Attrition)))
trainData = cs2data[trainIndices,]
testData = cs2data[-trainIndices,]
#KNN K = 3 with variables most correlated with Attrition
classificationsKNN3 = knn(trainData[,c("OT", "JobInvolvement", "U30", "JobLevel")], testData[,c("OT","JobInvolvement", "U30", "JobLevel")], trainData$Attrition, prob = TRUE,  k = 3)
#create confusion matrix for the given iteration
KNN3CM = confusionMatrix(classificationsKNN3, testData$Attrition)
# store model performance results
accKNNoriginal[s] = KNN3CM$overall[c("Accuracy")]
sensKNNoriginal[s] = KNN3CM$byClass[c("Sensitivity")]
specKNNoriginal[s] = KNN3CM$byClass[c("Specificity")]
# Get probability of Attrition
probAttr = ifelse(classificationsKNN3 == "Yes", attributes(classificationsKNN3)$prob, 1- attributes(classificationsKNN3)$prob)
# Lowering the threshold to .1591 which is the total of the 140 attrition records divided by the 870 total records. Lowering the threshold will increase the sensitivity (number of true positives), but lower the specificity (number of true negatives)
NewClassification = ifelse(probAttr > .125, "Yes", "No")
NC = table(NewClassification, testData$Attrition)
CM_AttrNC = confusionMatrix(table(relevel(as.factor(NewClassification), ref = "Yes"), testData$Attrition), mode = "everything")
# Print results of the confusionMatrix
# CM_AttrNC
# store model performance results
accKNNThreshold[s] = CM_AttrNC$overall[c("Accuracy")]
sensKNNThreshold[s] = CM_AttrNC$byClass[c("Sensitivity")]
specKNNThreshold[s] = CM_AttrNC$byClass[c("Specificity")]
}
# summary of model performance
print("Accuracy at K = 3")
summary(accKNNThreshold)
print("Sensitivity at K = 3")
summary(sensKNNThreshold)
print("Specificity at K = 3")
summary(specKNNThreshold)
# sum of how many times Sensitivity is below the threshold
sum(sensKNNThreshold < .6)
sum(sensKNNThreshold < .6) / iter
# sum of how many times specificity is below the threshold
sum(specKNNThreshold < .6)
sum(specKNNThreshold < .6) / iter
# Using a regression model to predict attrition using the binary variable AttrBin
# Set iteration counter
iter = 100
# create matrices to store the results
regAcc = matrix(nrow = iter)
regSens = matrix(nrow = iter)
regSpec = matrix(nrow = iter)
# Create Loop to measure across multiple iterations for model validation
for(s in 1:iter){
# set seed to s generate replicable for each iteration to measure model performance
set.seed(s)
# Set training and test data sets for the data
trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.7*length(cs2data$Attrition)))
trainData = cs2data[trainIndices,]
testData = cs2data[-trainIndices,]
# Create regression model using the test and training data
attrModel = lm(AttrBin ~ OT + JobLevel + JobInvolvement + U30, data = trainData)
attrPreds = predict(attrModel, newdata = testData)
# Setting a variable to predict attrition if the predicted value from the linear regression model is greater than the 140 / 870 or attrition / total records. This is equal to approximately 16%, and then tweaking to adjust the sensitivity and specificity.
attrClassificationPreds = ifelse(attrPreds >= .2, "Yes", "No")
testData$attrPreds = attrPreds
# set to a factor to store the results
attrClassificationPreds = factor(attrClassificationPreds, levels = c("Yes", "No"))
# create a confusionMatrix
CMAttrReg = confusionMatrix(attrClassificationPreds, testData$Attrition)
# store the results of the model
regAcc[s] = CMAttrReg$overall[c("Accuracy")]
regSens[s] = CMAttrReg$byClass[c("Sensitivity")]
regSpec[s] = CMAttrReg$byClass[c("Specificity")]
}
# print results
print("Accuracy")
summary(regAcc)
print("Sensitivity")
summary(regSens)
print("Specificity")
summary(regSpec)
summary(attrModel)
regacc
regAcc
regAcc
regSens
regSpec
# print results
print("Accuracy")
summary(regAcc)
print("Sensitivity")
summary(regSens)
print("Specificity")
summary(regSpec)
tst = read.csv("https://msdsds6306.s3.us-east-2.amazonaws.com/Case2PredictionsClassifyEXAMPLE.csv")
compClassData$MF = ifelse(compClassData$Gender == "Male", 1, 0)
compClassData$OT = ifelse(compClassData$OverTime == "Yes", 1, 0)
compClassData$Married = ifelse(compClassData$MaritalStatus == "Married", 1, 0)
compClassData$Divorced = ifelse(compClassData$MaritalStatus == "Divorced", 1, 0)
compClassData$U30 = ifelse(compClassData$Age < 30, 1, 0)
compClassData$U35 = ifelse(compClassData$Age < 35, 1, 0)
compClassData$Sales= ifelse(compClassData$Department == "Sales", 1, 0)
# Set seed for reproducibility - Best seed was 76
set.seed(76)
# Set training and test data sets for the data
trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.7*length(cs2data$Attrition)))
trainData = cs2data[trainIndices,]
testData = cs2data[-trainIndices,]
#KNN K = 3 with variables most correlated with Attrition
compKNN3 = knn(cs2data[,c("OT", "JobInvolvement", "JobLevel", "U30")], compClassData[,c("OT","JobInvolvement", "JobLevel", "U30")], cs2data$Attrition, prob = TRUE,  k = 3)
probCompAttr = ifelse(compKNN3 == "Yes", attributes(compKNN3)$prob, 1 - attributes(compKNN3)$prob)
# Lowering the threshold to .1591 which is the total of the 140 attrition records divided by the 870 total records. Lowering the threshold will increase the sensitivity (number of true positives), but lower the specificity (number of true negatives)
compNewKNN = ifelse(probCompAttr > .2, "Yes", "No")
compClassData$AttKNN = compNewKNN
compClassData$AttKNN = factor(compClassData$Attrition, levels =  c("Yes", "No"))
compClassData$AttKNN = factor(compClassData$probCompAttr, levels =  c("Yes", "No"))
#KNN K = 3 with variables most correlated with Attrition
compKNN3 = knn(trainData[,c("OT", "JobInvolvement", "JobLevel", "U30")], compClassData[,c("OT","JobInvolvement", "JobLevel", "U30")], testData$Attrition, prob = TRUE,  k = 3)
#KNN K = 3 with variables most correlated with Attrition
compKNN3 = knn(cs2data[,c("OT", "JobInvolvement", "JobLevel", "U30")], compClassData[,c("OT","JobInvolvement", "JobLevel", "U30")], cs2data$Attrition, prob = TRUE,  k = 3)
probCompAttr = ifelse(compKNN3 == "Yes", attributes(compKNN3)$prob, 1 - attributes(compKNN3)$prob)
# Set seed for reproducibility - Best seed was 76
set.seed(76)
# Set training and test data sets for the data
trainIndices = sample(seq(1:length(cs2data$Attrition)),round(.7*length(cs2data$Attrition)))
trainData = cs2data[trainIndices,]
testData = cs2data[-trainIndices,]
#KNN K = 3 with variables most correlated with Attrition
compKNN3 = knn(cs2data[,c("OT", "JobInvolvement", "JobLevel", "U30")], compClassData[,c("OT","JobInvolvement", "JobLevel", "U30")], cs2data$Attrition, prob = TRUE,  k = 3)
probCompAttr = ifelse(compKNN3 == "Yes", attributes(compKNN3)$prob, 1 - attributes(compKNN3)$prob)
# Lowering the threshold to .125, which is best threshold found when testing the models above.
compNewKNN = ifelse(probCompAttr > .125, "Yes", "No")
compClassData$AttKNN = compNewKNN
compClassData$AttKNN = factor(compClassData$probCompAttr, levels =  c("Yes", "No"))
compClassData$AttKNN = factor(compClassData$AttKNN, levels =  c("Yes", "No"))
summary(compClassData$AttKNN)
attrCModel = lm(AttrBin ~ OT + JobInvolvement+ U30 + JobLevel, data = cs2data)
attrCPreds = predict(attrCModel, newdata = compClassData)
compClassData$RegPreds = attrCPreds
# Setting a variable to predict attrition if the predicted value from the linear regression model is greater than .2, the threshold used in the test and training models.
attrClassPreds = ifelse(attrCPreds >= .20, "Yes", "No")
# set to a factor to store the results
attrClassPreds = factor(attrClassPreds, levels = c("Yes", "No"))
# View the results
summary(attrClassPreds)
compClassData$Attrition = attrClassPreds
compClassData$AttrBinPred = ifelse(attrCPreds >= .20, 1, 0)
# View the results
summary(attrClassPreds)
compClassData %>% select(c("ID","Attrition")) %>% write.csv(file = "Case2PredictionsKunz Attritition.csv", row.names = FALSE)
shiny::runApp('C:/Users/tkchu/Downloads/RShinyApp')
